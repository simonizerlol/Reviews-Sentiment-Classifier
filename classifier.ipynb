{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "H-8wMRchJAda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from collections import Counter\n",
        "import sklearn.metrics\n",
        "import sklearn.naive_bayes\n",
        "import sklearn.tree\n",
        "import sklearn.svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oTizi0NMJAdd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# read yelp and imdb csv files\n",
        "yelp_test = pd.read_csv('given_yelp-test.txt', sep = \"\\t\", header = None)\n",
        "yelp_train = pd.read_csv('given_yelp-train.txt', sep = \"\\t\", header = None)\n",
        "yelp_valid = pd.read_csv('given_yelp-valid.txt', sep = \"\\t\", header = None)\n",
        "\n",
        "imdb_test = pd.read_csv('given_IMDB-test.txt', sep = \"\\t\", header = None)\n",
        "imdb_train = pd.read_csv('given_IMDB-train.txt', sep = \"\\t\", header = None)\n",
        "imdb_valid = pd.read_csv('given_IMDB-valid.txt', sep = \"\\t\", header = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V9MyfrTYJAdg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# question 1: convert the review to a fixed length vector representation(binary bag-of-words and frequency bag-of-words)\n",
        "# convert both the datasets into both these representations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wn4zQ6yaJAdj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pick top 10,000 words in the vocabulary and ignore the rest of the words\n",
        "def pickTopWords(reviews):\n",
        "    words = []\n",
        "    topWords = []\n",
        "    \n",
        "    for review in reviews[0]:\n",
        "        # required tasks: punctuation removal and lower-casing the words\n",
        "        words.extend(review.lower().translate(str.maketrans(\"\",\"\", string.punctuation)).split(' '))\n",
        "    \n",
        "    ctr = Counter()\n",
        "    for word in words:\n",
        "        if (word != ''):\n",
        "            ctr[word] += 1\n",
        "        \n",
        "    topWords = ctr.most_common(10000) # pick top 10,000 words\n",
        "    return {tupl[0]: index for index, tupl in enumerate(topWords)}, [tupl[0] + '\\t' + str(index) + '\\t' + str(tupl[1])  for index, tupl in enumerate(topWords)]\n",
        "    \n",
        "# we only need to consider the training set\n",
        "yelp_topWords, yelp_output = pickTopWords(yelp_train)\n",
        "imdb_topWords, imdb_output = pickTopWords(imdb_train)\n",
        "\n",
        "# save the vocabulary of the two datasets into .txt files\n",
        "f = open(\"yelp-vocab.txt\", 'w',encoding='utf-8')\n",
        "ctr = 0\n",
        "for line in yelp_output:\n",
        "    if ctr == 0:  \n",
        "        f.write(line)\n",
        "    else:\n",
        "        f.write('\\n')\n",
        "        f.write(line)\n",
        "    ctr += 1\n",
        "f.close()\n",
        "\n",
        "f = open(\"IMDB-vocab.txt\", 'w',encoding='utf-8')\n",
        "ctr = 0\n",
        "for line in imdb_output:\n",
        "    if ctr == 0:  \n",
        "        f.write(line)\n",
        "    else:\n",
        "        f.write('\\n')\n",
        "        f.write(line)\n",
        "    ctr += 1\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2WR8kEooJAdm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# each word in the vocabulary has a corresponding numeric id and frequency all tab separated\n",
        "def saveReviewsIDs(dic, reviews, filename):\n",
        "    f = open(filename, 'w',encoding='utf-8')\n",
        "    ctr = 0\n",
        "\n",
        "    for review, categ in zip(reviews[0], reviews[1]):\n",
        "        if ctr != 0:\n",
        "            f.write('\\n')\n",
        "\n",
        "        r = review.lower().translate(str.maketrans(\"\",\"\", string.punctuation)).split(' ')\n",
        "\n",
        "        for index, word in enumerate(r):\n",
        "            if word in dic:\n",
        "                if index != 0:\n",
        "                    f.write(' ')\n",
        "                f.write(str(dic[word]))\n",
        "        f.write('\\t')\n",
        "        f.write(str(categ))\n",
        "        ctr += 1\n",
        "\n",
        "    f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xsoh-qljJAdp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saveReviewsIDs(yelp_topWords, yelp_test, \"yelp-test.txt\")\n",
        "saveReviewsIDs(yelp_topWords, yelp_train, \"yelp-train.txt\")\n",
        "saveReviewsIDs(yelp_topWords, yelp_valid, \"yelp-valid.txt\")\n",
        "\n",
        "saveReviewsIDs(imdb_topWords, imdb_test, \"IMDB-test.txt\")\n",
        "saveReviewsIDs(imdb_topWords, imdb_train, \"IMDB-train.txt\")\n",
        "saveReviewsIDs(imdb_topWords, imdb_valid, \"IMDB-valid.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y13qFjnnJAds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for each of the top 10000 words, there is one corresponding dimension in the feature vector \n",
        "# that is 1 if the example contains the word, and 0 otherwise\n",
        "def bin_bow_vector_gen(topWords, reviews):\n",
        "    m = []\n",
        "    for review in reviews[0]:\n",
        "        vector = [0] * len(topWords)\n",
        "        for word in review:\n",
        "            if word in topWords:\n",
        "                vector[topWords[word]] = 1\n",
        "        m.append(vector)\n",
        "    return np.array(m)\n",
        "\n",
        "# for each of the 10000 words, the corresponding feature is the frequency of occurrence of that word in the given review.\n",
        "# calculate the frequency by summing the occurences of words in a review\n",
        "# and then divide by the sum of occurrences of all 10000 words so that the vector for each example sums to 1\n",
        "def freq_bow_vector_gen(topWords, reviews):\n",
        "    m = []\n",
        "    for review in reviews[0]:\n",
        "        vector = [0] * len(topWords)\n",
        "        for word in review:\n",
        "            if word in topWords:\n",
        "                vector[topWords[word]] += 1\n",
        "                \n",
        "        s = sum(vector)\n",
        "        if s > 0:\n",
        "            vector = np.divide(vector, s)\n",
        "        m.append(vector)\n",
        "    return np.array(m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-yw4Hl-gJAdv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert both the datasets into both these representations\n",
        "yelp_train_bin_bow = bin_bow_vector_gen(yelp_topWords, yelp_train)\n",
        "yelp_test_bin_bow = bin_bow_vector_gen(yelp_topWords, yelp_test)\n",
        "yelp_valid_bin_bow = bin_bow_vector_gen(yelp_topWords, yelp_valid)\n",
        "\n",
        "yelp_train_freq_bow = freq_bow_vector_gen(yelp_topWords, yelp_train)\n",
        "yelp_test_freq_bow = freq_bow_vector_gen(yelp_topWords, yelp_test)\n",
        "yelp_valid_freq_bow = freq_bow_vector_gen(yelp_topWords, yelp_valid)\n",
        "\n",
        "imdb_train_bin_bow = bin_bow_vector_gen(imdb_topWords, imdb_train)\n",
        "imdb_test_bin_bow = bin_bow_vector_gen(imdb_topWords, imdb_test)\n",
        "imdb_valid_bin_bow = bin_bow_vector_gen(imdb_topWords, imdb_valid)\n",
        "\n",
        "imdb_train_freq_bow = freq_bow_vector_gen(imdb_topWords, imdb_train)\n",
        "imdb_test_freq_bow = freq_bow_vector_gen(imdb_topWords, imdb_test)\n",
        "imdb_valid_freq_bow = freq_bow_vector_gen(imdb_topWords, imdb_valid)\n",
        "\n",
        "# end of question 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J2DfeMuaJAdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# question 2: yelp dataset with binary bag-of-words representation\n",
        "# use the F1-measure as the evaluation metric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QFvTwBGrJAd1",
        "colab_type": "code",
        "colab": {},
        "outputId": "e0e2f870-4cc5-4596-c874-417854605d85"
      },
      "cell_type": "code",
      "source": [
        "# report the performance of the random classifier\n",
        "random = np.random.choice([1,2,3,4,5], len(yelp_test[1]))\n",
        "sklearn.metrics.f1_score(yelp_test[1], random, average = 'micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1955"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "FEjubV_QJAd4",
        "colab_type": "code",
        "colab": {},
        "outputId": "5596d53f-8f79-437d-a5b8-5b282e0067c5"
      },
      "cell_type": "code",
      "source": [
        "# report the performance of the majority-class classifier\n",
        "majority = np.argmax(np.bincount(yelp_train[1]))\n",
        "majority_array = np.array([majority]*len(yelp_test[1]))\n",
        "sklearn.metrics.f1_score(yelp_test[1], majority_array, average = 'micro')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "R9y8i-NXJAd7",
        "colab_type": "code",
        "colab": {},
        "outputId": "f9da42fa-5299-4564-94d4-e42e01c58786"
      },
      "cell_type": "code",
      "source": [
        "# train Naive Bayes with Bernoulli Naive Bayes\n",
        "BNB = sklearn.naive_bayes.BernoulliNB()\n",
        "BNB.fit(yelp_train_bin_bow, yelp_train[1])\n",
        "predictions = BNB.predict(yelp_test_bin_bow)\n",
        "sklearn.metrics.f1_score(yelp_test[1], predictions, average = 'micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3645"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "D2ASxwMqJAd-",
        "colab_type": "code",
        "colab": {},
        "outputId": "d909ea7a-fe55-4451-deff-bfd716b0234a"
      },
      "cell_type": "code",
      "source": [
        "# Naive Bayes hyper-parameter tuning\n",
        "alphas = np.linspace(2, 4, 50)\n",
        "f1s = []\n",
        "for a in alphas:\n",
        "    BNB = sklearn.naive_bayes.BernoulliNB(alpha = a)\n",
        "    BNB.fit(yelp_train_bin_bow, yelp_train[1])\n",
        "    predictions = BNB.predict(yelp_valid_bin_bow)\n",
        "    f1s.append(sklearn.metrics.f1_score(yelp_valid[1], predictions, average = 'micro'))\n",
        "\n",
        "bestAlpha = alphas[np.argmax(f1s)]\n",
        "print(\"The best alpha is \" + str(bestAlpha))\n",
        "print(\"The maximum F-Measure for valid is \" + str(np.max(f1s)))\n",
        "\n",
        "BNB = sklearn.naive_bayes.BernoulliNB(alpha = bestAlpha)\n",
        "BNB.fit(yelp_train_bin_bow, yelp_train[1])\n",
        "predictions = BNB.predict(yelp_test_bin_bow)\n",
        "print(\"The F-Measure for test is \" + str(sklearn.metrics.f1_score(yelp_test[1], predictions, average = 'micro')))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best alpha is 2.693877551020408\n",
            "The maximum F-Measure for valid is 0.369\n",
            "The F-Measure for test is 0.36250000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g8r4sWw-JAeE",
        "colab_type": "code",
        "colab": {},
        "outputId": "2edd2ed2-92ac-4906-baf5-104d5c2b9ed6"
      },
      "cell_type": "code",
      "source": [
        "# train Decision Trees\n",
        "DT = sklearn.tree.DecisionTreeClassifier()\n",
        "DT.fit(yelp_train_bin_bow, yelp_train[1])\n",
        "predictions = DT.predict(yelp_test_bin_bow)\n",
        "sklearn.metrics.f1_score(yelp_test[1], predictions, average = 'micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "lBaP13HkJAeH",
        "colab_type": "code",
        "colab": {},
        "outputId": "dc1ae89a-b0d7-4ae4-f8b4-74142449d140"
      },
      "cell_type": "code",
      "source": [
        "# Decision Trees hyper-parameter tuning\n",
        "f1s = []\n",
        "criterion = [\"gini\", \"entropy\"]\n",
        "splitter = [\"best\", \"random\"]\n",
        "\n",
        "for c in criterion:\n",
        "    for s in splitter:\n",
        "        DT = sklearn.tree.DecisionTreeClassifier(criterion = c, splitter = s)\n",
        "        DT.fit(yelp_train_bin_bow, yelp_train[1])\n",
        "        predictions = DT.predict(yelp_valid_bin_bow)\n",
        "        f1s.append(sklearn.metrics.f1_score(yelp_valid[1], predictions, average = 'micro'))\n",
        "        \n",
        "highestF1 = np.max(f1s)\n",
        "print(\"The highest F-Measure for valid is \"+ str(highestF1))\n",
        "arg = np.argmax(f1s)\n",
        "if arg == 0 or arg == 1:\n",
        "    c = \"gini\"\n",
        "else:\n",
        "    c = \"entropy\"\n",
        "if arg == 0 or arg == 2:\n",
        "    s = \"best\"\n",
        "else:\n",
        "    s = \"random\"\n",
        "    \n",
        "print(\"For criteria \" + str(c) + \" and splitter \" + str(s))\n",
        "\n",
        "DT = sklearn.tree.DecisionTreeClassifier(criterion = c, splitter = s)\n",
        "DT.fit(yelp_train_bin_bow, yelp_train[1])\n",
        "predictions = DT.predict(yelp_test_bin_bow)\n",
        "print(\"the F-Measure for test is \" + str(sklearn.metrics.f1_score(yelp_test[1], predictions, average = 'micro')))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The highest F-Measure for valid is 0.313\n",
            "For criteria entropy and splitter random\n",
            "the F-Measure for test is 0.3265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7IlnxTkSJAeL",
        "colab_type": "code",
        "colab": {},
        "outputId": "7629474e-de3b-4d54-e3ff-e7dbf0b0e716"
      },
      "cell_type": "code",
      "source": [
        "# train Linear SVM\n",
        "svm = sklearn.svm.LinearSVC()\n",
        "svm.fit(yelp_train_bin_bow, yelp_train[1])\n",
        "predictions = svm.predict(yelp_test_bin_bow)\n",
        "sklearn.metrics.f1_score(yelp_test[1], predictions, average = 'micro')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37050000000000005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "FcFNs1bjJAeO",
        "colab_type": "code",
        "colab": {},
        "outputId": "df6ed586-42c5-480a-bca2-6bef076ec435"
      },
      "cell_type": "code",
      "source": [
        "# Linear SVM hyper-parameter tuning\n",
        "f1s = []\n",
        "penalty = [\"l1\", \"l2\"]\n",
        "loss = [\"hinge\", \"squared_hinge\"]\n",
        "\n",
        "for p in penalty:\n",
        "    if p == \"l1\": # combination of \"l1\" and (\"hinge\" or \"squared_hinge\") is not supported\n",
        "        svm = sklearn.svm.LinearSVC(penalty = p, dual = False)\n",
        "        svm.fit(yelp_train_bin_bow, yelp_train[1])\n",
        "        predictions = svm.predict(yelp_valid_bin_bow)\n",
        "        f1s.append(sklearn.metrics.f1_score(yelp_valid[1], predictions, average = 'micro'))\n",
        "    else:\n",
        "        for l in loss:\n",
        "            svm = sklearn.svm.LinearSVC(penalty = p, loss = l)\n",
        "            svm.fit(yelp_train_bin_bow, yelp_train[1])\n",
        "            predictions = svm.predict(yelp_valid_bin_bow)\n",
        "            f1s.append(sklearn.metrics.f1_score(yelp_valid[1], predictions, average = 'micro'))\n",
        "        \n",
        "highestF1 = np.max(f1s)\n",
        "print(\"The highest F-Measure for valid is \"+ str(highestF1))\n",
        "arg = np.argmax(f1s)\n",
        "if arg == 0:\n",
        "    p = \"l1\"\n",
        "    l = \"-\"\n",
        "elif arg == 1:\n",
        "    p = \"l2\"\n",
        "    l = \"hinge\"\n",
        "elif arg == 2:\n",
        "    p = \"l2\"\n",
        "    l = \"squared_hinge\"\n",
        "    \n",
        "print(\"For penalty \" + str(p) + \" and loss \" + str(l))\n",
        "\n",
        "if l == \"-\":\n",
        "    svm = sklearn.svm.LinearSVC(penalty = p, dual = False)\n",
        "else:\n",
        "    svm = sklearn.svm.LinearSVC(penalty = p, loss = l)\n",
        "svm.fit(yelp_train_bin_bow, yelp_train[1])\n",
        "predictions = svm.predict(yelp_test_bin_bow)\n",
        "print(\"the F-Measure for test is \" + str(sklearn.metrics.f1_score(yelp_test[1], predictions, average = 'micro')))\n",
        "\n",
        "# end of question 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The highest F-Measure for valid is 0.347\n",
            "For penalty l1 and loss -\n",
            "the F-Measure for test is 0.3685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-ocgOY8wJAeR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# question 3: repeat question 2 but with frequency bag-of-words representation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sz8EFvQ9JAeT",
        "colab_type": "code",
        "colab": {},
        "outputId": "71126f06-7987-4169-dce5-90f9d0271234"
      },
      "cell_type": "code",
      "source": [
        "# train Naive Bayes with Gaussian Naive Bayes\n",
        "GNB = sklearn.naive_bayes.GaussianNB()\n",
        "GNB.fit(yelp_train_freq_bow, yelp_train[1])\n",
        "predictions = GNB.predict(yelp_test_freq_bow)\n",
        "sklearn.metrics.f1_score(yelp_test[1], predictions, average = 'micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2865"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "ir8DTbmQJAeW",
        "colab_type": "code",
        "colab": {},
        "outputId": "7bcb6255-7ab1-487e-af26-54edf413ef18"
      },
      "cell_type": "code",
      "source": [
        "# train Decision Trees\n",
        "DT = sklearn.tree.DecisionTreeClassifier()\n",
        "DT.fit(yelp_train_freq_bow, yelp_train[1])\n",
        "predictions = DT.predict(yelp_test_freq_bow)\n",
        "sklearn.metrics.f1_score(yelp_test[1], predictions, average = 'micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "N3PmXJfmJAeY",
        "colab_type": "code",
        "colab": {},
        "outputId": "a15cb871-e45d-4a3b-f796-166b9a2eea8a"
      },
      "cell_type": "code",
      "source": [
        "# Decision Trees hyper-parameter tuning\n",
        "f1s = []\n",
        "criterion = [\"gini\", \"entropy\"]\n",
        "splitter = [\"best\", \"random\"]\n",
        "\n",
        "for c in criterion:\n",
        "    for s in splitter:\n",
        "        DT = sklearn.tree.DecisionTreeClassifier(criterion = c, splitter = s)\n",
        "        DT.fit(yelp_train_freq_bow, yelp_train[1])\n",
        "        predictions = DT.predict(yelp_valid_freq_bow)\n",
        "        f1s.append(sklearn.metrics.f1_score(yelp_valid[1], predictions, average = 'micro'))\n",
        "        \n",
        "highestF1 = np.max(f1s)\n",
        "print(\"The highest F-Measure for valid is \"+ str(highestF1))\n",
        "arg = np.argmax(f1s)\n",
        "if arg == 0 or arg == 1:\n",
        "    c = \"gini\"\n",
        "else:\n",
        "    c = \"entropy\"\n",
        "if arg == 0 or arg == 2:\n",
        "    s = \"best\"\n",
        "else:\n",
        "    s = \"random\"\n",
        "    \n",
        "print(\"For criteria \" + str(c) + \" and splitter \" + str(s))\n",
        "\n",
        "DT = sklearn.tree.DecisionTreeClassifier(criterion = c, splitter = s)\n",
        "DT.fit(yelp_train_freq_bow, yelp_train[1])\n",
        "predictions = DT.predict(yelp_test_freq_bow)\n",
        "print(\"the F-Measure for test is \" + str(sklearn.metrics.f1_score(yelp_test[1], predictions, average = 'micro')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The highest F-Measure for valid is 0.28\n",
            "For criteria entropy and splitter random\n",
            "the F-Measure for test is 0.295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V5QicG5dJAeZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "196f7049-4533-446e-cc55-e6229c129f48"
      },
      "cell_type": "code",
      "source": [
        "# train Linear SVM\n",
        "svm = sklearn.svm.LinearSVC()\n",
        "svm.fit(yelp_train_freq_bow, yelp_train[1])\n",
        "predictions = svm.predict(yelp_test_freq_bow)\n",
        "sklearn.metrics.f1_score(yelp_test[1], predictions, average = 'micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39050000000000007"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "mPKAuxEpJAec",
        "colab_type": "code",
        "colab": {},
        "outputId": "d84bd508-92f7-4ebf-f10e-1d2637d6207f"
      },
      "cell_type": "code",
      "source": [
        "# Linear SVM hyper-parameter tuning\n",
        "f1s = []\n",
        "penalty = [\"l1\", \"l2\"]\n",
        "loss = [\"hinge\", \"squared_hinge\"]\n",
        "\n",
        "for p in penalty:\n",
        "    if p == \"l1\": # combination of \"l1\" and (\"hinge\" or \"squared_hinge\") is not supported\n",
        "        svm = sklearn.svm.LinearSVC(penalty = p, dual = False)\n",
        "        svm.fit(yelp_train_freq_bow, yelp_train[1])\n",
        "        predictions = svm.predict(yelp_valid_freq_bow)\n",
        "        f1s.append(sklearn.metrics.f1_score(yelp_valid[1], predictions, average = 'micro'))\n",
        "    else:\n",
        "        for l in loss:\n",
        "            svm = sklearn.svm.LinearSVC(penalty = p, loss = l)\n",
        "            svm.fit(yelp_train_freq_bow, yelp_train[1])\n",
        "            predictions = svm.predict(yelp_valid_freq_bow)\n",
        "            f1s.append(sklearn.metrics.f1_score(yelp_valid[1], predictions, average = 'micro'))\n",
        "        \n",
        "highestF1 = np.max(f1s)\n",
        "print(\"The highest F-Measure for valid is \"+ str(highestF1))\n",
        "arg = np.argmax(f1s)\n",
        "if arg == 0:\n",
        "    p = \"l1\"\n",
        "    l = \"-\"\n",
        "elif arg == 1:\n",
        "    p = \"l2\"\n",
        "    l = \"hinge\"\n",
        "elif arg == 2:\n",
        "    p = \"l2\"\n",
        "    l = \"squared_hinge\"\n",
        "    \n",
        "print(\"For penalty \" + str(p) + \" and loss \" + str(l))\n",
        "\n",
        "if l == \"-\":\n",
        "    svm = sklearn.svm.LinearSVC(penalty = p, dual = False)\n",
        "else:\n",
        "    svm = sklearn.svm.LinearSVC(penalty = p, loss = l)\n",
        "svm.fit(yelp_train_freq_bow, yelp_train[1])\n",
        "predictions = svm.predict(yelp_test_freq_bow)\n",
        "print(\"the F-Measure for test is \" + str(sklearn.metrics.f1_score(yelp_test[1], predictions, average = 'micro')))\n",
        "\n",
        "# end of question 3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The highest F-Measure for valid is 0.377\n",
            "For penalty l2 and loss squared_hinge\n",
            "the F-Measure for test is 0.39050000000000007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LVJ-zM3RJAef",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# question 4.1: repeat question 2 but with IMDB dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wM3befvnJAeg",
        "colab_type": "code",
        "colab": {},
        "outputId": "cbb5e805-d42e-4e9e-8074-ad43b76ac0d2"
      },
      "cell_type": "code",
      "source": [
        "# report the performance of the random classifier\n",
        "rand = np.random.choice([0,1], len(imdb_test[1]))\n",
        "sklearn.metrics.f1_score(imdb_test[1], rand, average = 'micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.50272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "KP75WQjQJAej",
        "colab_type": "code",
        "colab": {},
        "outputId": "20505157-ba4f-4b31-af09-66134faa6151"
      },
      "cell_type": "code",
      "source": [
        "# report the performance of the majority-class classifier\n",
        "majority = np.argmax(np.bincount(imdb_train[1]))\n",
        "majority_array = np.array([majority]*len(imdb_test[1]))\n",
        "sklearn.metrics.f1_score(imdb_test[1], majority_array, average = 'micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "XLxoU-nvJAem",
        "colab_type": "code",
        "colab": {},
        "outputId": "90664fd3-e7f3-4703-8ea0-00b4a1dc4237"
      },
      "cell_type": "code",
      "source": [
        "# train Naive Bayes with Bernoulli Naive Bayes\n",
        "BNB = sklearn.naive_bayes.BernoulliNB()\n",
        "BNB.fit(imdb_train_bin_bow, imdb_train[1])\n",
        "predictions = BNB.predict(imdb_test_bin_bow)\n",
        "sklearn.metrics.f1_score(imdb_test[1], predictions, average = 'micro')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.55116"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "xuDT4qK5JAen",
        "colab_type": "code",
        "colab": {},
        "outputId": "1f9e39df-e05b-407c-de62-1acc605a3759"
      },
      "cell_type": "code",
      "source": [
        "# Naive Bayes hyper-parameter tuning\n",
        "alphas = np.linspace(3, 5, 50)\n",
        "f1s = []\n",
        "for a in alphas:\n",
        "    BNB = sklearn.naive_bayes.BernoulliNB(alpha = a)\n",
        "    BNB.fit(imdb_train_bin_bow, imdb_train[1])\n",
        "    predictions = BNB.predict(imdb_valid_bin_bow)\n",
        "    f1s.append(sklearn.metrics.f1_score(imdb_valid[1], predictions, average = 'micro'))\n",
        "\n",
        "bestAlpha = alphas[np.argmax(f1s)]\n",
        "print(\"The best alpha is \" + str(bestAlpha))\n",
        "print(\"The maximum F-Measure for valid is \" + str(np.max(f1s)))\n",
        "\n",
        "BNB = sklearn.naive_bayes.BernoulliNB(alpha = bestAlpha)\n",
        "BNB.fit(imdb_train_bin_bow, imdb_train[1])\n",
        "predictions = BNB.predict(imdb_test_bin_bow)\n",
        "print(\"The F-Measure for test is \" + str(sklearn.metrics.f1_score(imdb_test[1], predictions, average = 'micro')))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best alpha is 3.979591836734694\n",
            "The maximum F-Measure for valid is 0.543\n",
            "The F-Measure for test is 0.5512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VfT9Ok0lJAeq",
        "colab_type": "code",
        "colab": {},
        "outputId": "3ebc75ad-fdac-4de4-d786-7c79afefe4f2"
      },
      "cell_type": "code",
      "source": [
        "# train Decision Trees\n",
        "DT = sklearn.tree.DecisionTreeClassifier()\n",
        "DT.fit(imdb_train_bin_bow, imdb_train[1])\n",
        "predictions = DT.predict(imdb_test_bin_bow)\n",
        "sklearn.metrics.f1_score(imdb_test[1], predictions, average = 'micro')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.53972"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "y2IeW1HyJAet",
        "colab_type": "code",
        "colab": {},
        "outputId": "3e9d0b36-1117-4090-aa4f-17a933cf6e08"
      },
      "cell_type": "code",
      "source": [
        "# Decision Trees hyper-parameter tuning\n",
        "f1s = []\n",
        "criterion = [\"gini\", \"entropy\"]\n",
        "splitter = [\"best\", \"random\"]\n",
        "\n",
        "for c in criterion:\n",
        "    for s in splitter:\n",
        "        DT = sklearn.tree.DecisionTreeClassifier(criterion = c, splitter = s)\n",
        "        DT.fit(imdb_train_bin_bow, imdb_train[1])\n",
        "        predictions = DT.predict(imdb_valid_bin_bow)\n",
        "        f1s.append(sklearn.metrics.f1_score(imdb_valid[1], predictions, average = 'micro'))\n",
        "        \n",
        "highestF1 = np.max(f1s)\n",
        "print(\"The highest F-Measure for valid is \"+ str(highestF1))\n",
        "arg = np.argmax(f1s)\n",
        "if arg == 0 or arg == 1:\n",
        "    c = \"gini\"\n",
        "else:\n",
        "    c = \"entropy\"\n",
        "if arg == 0 or arg == 2:\n",
        "    s = \"best\"\n",
        "else:\n",
        "    s = \"random\"\n",
        "    \n",
        "print(\"For criteria \" + str(c) + \" and splitter \" + str(s))\n",
        "\n",
        "DT = sklearn.tree.DecisionTreeClassifier(criterion = c, splitter = s)\n",
        "DT.fit(imdb_train_bin_bow, imdb_train[1])\n",
        "predictions = DT.predict(imdb_test_bin_bow)\n",
        "print(\"the F-Measure for test is \" + str(sklearn.metrics.f1_score(imdb_test[1], predictions, average = 'micro')))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The highest F-Measure for valid is 0.537\n",
            "For criteria entropy and splitter random\n",
            "the F-Measure for test is 0.53988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UjDEf4rhJAew",
        "colab_type": "code",
        "colab": {},
        "outputId": "77da5ad3-31de-475d-94c4-6fdc455cd6a2"
      },
      "cell_type": "code",
      "source": [
        "# train Linear SVM\n",
        "svm = sklearn.svm.LinearSVC()\n",
        "svm.fit(imdb_train_bin_bow, imdb_train[1])\n",
        "predictions = svm.predict(imdb_test_bin_bow)\n",
        "sklearn.metrics.f1_score(imdb_test[1], predictions, average = 'micro')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.55664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "7rylDQg8JAez",
        "colab_type": "code",
        "colab": {},
        "outputId": "0151a99a-ab3d-4f72-a4d3-30d0dc9857bc"
      },
      "cell_type": "code",
      "source": [
        "# Linear SVM hyper-parameter tuning\n",
        "f1s = []\n",
        "penalty = [\"l1\", \"l2\"]\n",
        "loss = [\"hinge\", \"squared_hinge\"]\n",
        "\n",
        "for p in penalty:\n",
        "    if p == \"l1\": # combination of \"l1\" and (\"hinge\" or \"squared_hinge\") is not supported\n",
        "        svm = sklearn.svm.LinearSVC(penalty = p, dual = False)\n",
        "        svm.fit(imdb_train_bin_bow, imdb_train[1])\n",
        "        predictions = svm.predict(imdb_valid_bin_bow)\n",
        "        f1s.append(sklearn.metrics.f1_score(imdb_valid[1], predictions, average = 'micro'))\n",
        "    else:\n",
        "        for l in loss:\n",
        "            svm = sklearn.svm.LinearSVC(penalty = p, loss = l)\n",
        "            svm.fit(imdb_train_bin_bow, imdb_train[1])\n",
        "            predictions = svm.predict(imdb_valid_bin_bow)\n",
        "            f1s.append(sklearn.metrics.f1_score(imdb_valid[1], predictions, average = 'micro'))\n",
        "        \n",
        "highestF1 = np.max(f1s)\n",
        "print(\"The highest F-Measure for valid is \"+ str(highestF1))\n",
        "arg = np.argmax(f1s)\n",
        "if arg == 0:\n",
        "    p = \"l1\"\n",
        "    l = \"-\"\n",
        "elif arg == 1:\n",
        "    p = \"l2\"\n",
        "    l = \"hinge\"\n",
        "elif arg == 2:\n",
        "    p = \"l2\"\n",
        "    l = \"squared_hinge\"\n",
        "    \n",
        "print(\"For penalty \" + str(p) + \" and loss \" + str(l))\n",
        "\n",
        "if l == \"-\":\n",
        "    svm = sklearn.svm.LinearSVC(penalty = p, dual = False)\n",
        "else:\n",
        "    svm = sklearn.svm.LinearSVC(penalty = p, loss = l)\n",
        "svm.fit(imdb_train_bin_bow, imdb_train[1])\n",
        "predictions = svm.predict(imdb_test_bin_bow)\n",
        "print(\"the F-Measure for test is \" + str(sklearn.metrics.f1_score(imdb_test[1], predictions, average = 'micro')))\n",
        "\n",
        "# end of question 4.1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The highest F-Measure for valid is 0.5508\n",
            "For penalty l2 and loss hinge\n",
            "the F-Measure for test is 0.55628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IqyuymWyJAe1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# question 4.2: repeat question 3 but with IMDB dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aH1aPFqJJAe3",
        "colab_type": "code",
        "colab": {},
        "outputId": "3b7c99cd-9be8-47a7-91c2-02b1b1872cff"
      },
      "cell_type": "code",
      "source": [
        "# train Naive Bayes with Gaussian Naive Bayes\n",
        "GNB = sklearn.naive_bayes.GaussianNB()\n",
        "GNB.fit(imdb_train_freq_bow, imdb_train[1])\n",
        "predictions = GNB.predict(imdb_test_freq_bow)\n",
        "sklearn.metrics.f1_score(imdb_test[1], predictions, average = 'micro')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.51632"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "2xEWtJtwJAe7",
        "colab_type": "code",
        "colab": {},
        "outputId": "d0517e6a-bb05-4b4d-ac96-89aad6f950fa"
      },
      "cell_type": "code",
      "source": [
        "# train Decision Trees\n",
        "DT = sklearn.tree.DecisionTreeClassifier()\n",
        "DT.fit(imdb_train_freq_bow, imdb_train[1])\n",
        "predictions = DT.predict(imdb_test_freq_bow)\n",
        "sklearn.metrics.f1_score(imdb_test[1], predictions, average = 'micro')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "W79YJdY_JAe-",
        "colab_type": "code",
        "colab": {},
        "outputId": "a075d0f0-8757-4fb7-efdf-ad08d3bc8c26"
      },
      "cell_type": "code",
      "source": [
        "# Decision Trees hyper-parameter tuning\n",
        "f1s = []\n",
        "criterion = [\"gini\", \"entropy\"]\n",
        "splitter = [\"best\", \"random\"]\n",
        "\n",
        "for c in criterion:\n",
        "    for s in splitter:\n",
        "        DT = sklearn.tree.DecisionTreeClassifier(criterion = c, splitter = s)\n",
        "        DT.fit(imdb_train_freq_bow, imdb_train[1])\n",
        "        predictions = DT.predict(imdb_valid_freq_bow)\n",
        "        f1s.append(sklearn.metrics.f1_score(imdb_valid[1], predictions, average = 'micro'))\n",
        "        \n",
        "highestF1 = np.max(f1s)\n",
        "print(\"The highest F-Measure for valid is \"+ str(highestF1))\n",
        "arg = np.argmax(f1s)\n",
        "if arg == 0 or arg == 1:\n",
        "    c = \"gini\"\n",
        "else:\n",
        "    c = \"entropy\"\n",
        "if arg == 0 or arg == 2:\n",
        "    s = \"best\"\n",
        "else:\n",
        "    s = \"random\"\n",
        "    \n",
        "print(\"For criteria \" + str(c) + \" and splitter \" + str(s))\n",
        "\n",
        "DT = sklearn.tree.DecisionTreeClassifier(criterion = c, splitter = s)\n",
        "DT.fit(imdb_train_freq_bow, imdb_train[1])\n",
        "predictions = DT.predict(imdb_test_freq_bow)\n",
        "print(\"the F-Measure for test is \" + str(sklearn.metrics.f1_score(imdb_test[1], predictions, average = 'micro')))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The highest F-Measure for valid is 0.5493\n",
            "For criteria entropy and splitter best\n",
            "the F-Measure for test is 0.5408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "noXaRloAJAfB",
        "colab_type": "code",
        "colab": {},
        "outputId": "ceacbba9-60a4-48c0-917d-b63f258229b0"
      },
      "cell_type": "code",
      "source": [
        "# train Linear SVM\n",
        "svm = sklearn.svm.LinearSVC()\n",
        "svm.fit(imdb_train_freq_bow, imdb_train[1])\n",
        "predictions = svm.predict(imdb_test_freq_bow)\n",
        "sklearn.metrics.f1_score(imdb_test[1], predictions, average = 'micro')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.61228"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "lAs0_8doJAfD",
        "colab_type": "code",
        "colab": {},
        "outputId": "60900eb4-057d-4cad-94dd-d1b8afc8d8a8"
      },
      "cell_type": "code",
      "source": [
        "# Linear SVM hyper-parameter tuning\n",
        "f1s = []\n",
        "penalty = [\"l1\", \"l2\"]\n",
        "loss = [\"hinge\", \"squared_hinge\"]\n",
        "\n",
        "for p in penalty:\n",
        "    if p == \"l1\": # combination of \"l1\" and (\"hinge\" or \"squared_hinge\") is not supported\n",
        "        svm = sklearn.svm.LinearSVC(penalty=p, dual=False)\n",
        "        svm.fit(imdb_train_freq_bow, imdb_train[1])\n",
        "        predictions = svm.predict(imdb_valid_freq_bow)\n",
        "        f1s.append(sklearn.metrics.f1_score(imdb_valid[1], predictions, average = 'micro'))\n",
        "    else:\n",
        "        for l in loss:\n",
        "            svm = sklearn.svm.LinearSVC(penalty=p, loss=l)\n",
        "            svm.fit(imdb_train_freq_bow, imdb_train[1])\n",
        "            predictions = svm.predict(imdb_valid_freq_bow)\n",
        "            f1s.append(sklearn.metrics.f1_score(imdb_valid[1], predictions, average = 'micro'))\n",
        "        \n",
        "highestF1 = np.max(f1s)\n",
        "print(\"The highest F-Measure for valid is \"+ str(highestF1))\n",
        "arg = np.argmax(f1s)\n",
        "if arg == 0:\n",
        "    p = \"l1\"\n",
        "    l = \"-\"\n",
        "elif arg == 1:\n",
        "    p = \"l2\"\n",
        "    l = \"hinge\"\n",
        "elif arg == 2:\n",
        "    p = \"l2\"\n",
        "    l = \"squared_hinge\"\n",
        "    \n",
        "print(\"For penalty \" + str(p) + \" and loss \" + str(l))\n",
        "\n",
        "if l == \"-\":\n",
        "    svm = sklearn.svm.LinearSVC(penalty = p, dual = False)\n",
        "else:\n",
        "    svm = sklearn.svm.LinearSVC(penalty = p, loss = l)\n",
        "svm.fit(imdb_train_freq_bow, imdb_train[1])\n",
        "predictions = svm.predict(imdb_test_freq_bow)\n",
        "print(\"the F-Measure for test is \" + str(sklearn.metrics.f1_score(imdb_test[1], predictions, average = 'micro')))\n",
        "\n",
        "# end of question 4.2\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The highest F-Measure for valid is 0.6205\n",
            "For penalty l1 and loss -\n",
            "the F-Measure for test is 0.61676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2gPoHEI7JAfE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}